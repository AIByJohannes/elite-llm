# elite-llm
Inference server for PCs running QNN NPUs
